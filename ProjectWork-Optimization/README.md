# Проектная работа по курсу - Оптимизация настроек кластера, структуры БД и запросов, для повышения производительности при работе с большими данными.

## Введение

Современные базы данных играют ключевую роль в обработке и анализе больших объемов информации. Одной из наиболее популярных систем управления базами данных (СУБД) является PostgreSQL, известная своей расширяемостью, мощными возможностями индексирования и поддержкой сложных аналитических запросов. Однако производительность PostgreSQL по умолчанию не всегда является оптимальной и требует дополнительной настройки в зависимости от характеристик сервера и специфики нагрузки.

В данной работе рассматривается процесс оптимизации кластера PostgreSQL и запросов к нему на примере обработки данных из набора "Animes Dataset 2023" с платформы Kaggle. Данный дата-сет представляет собой выгрузку открытых данных с сайта myanimelist.net. Оптимизация включает в себя настройку параметров PostgreSQL, создание индексов, анализ и улучшение запросов, а также другие мероприятия, направленные на повышение производительности системы.

**Исходные данные загружаются в базу данных из трех CSV-файлов:**
- `anime-transformed-dataset-2023.csv` - 23748 записей. Представляет список всех анмие и информацию по ним. 
- `users-details-transformed-2023.csv` - 731282 записей. Представляет список всех пользователей и открытую информацию по ним.
- `users-scores-transformed-2023.csv`  - 23796586 записей. Является сводным списком, в котором предоставлена информация о том какой пользователь какому аниме какую оценку поставил.  

Анализ эффективности оптимизации проводится с использованием инструмента `EXPLAIN ANALYZE`, позволяющего оценить планы выполнения запросов и время их обработки. Основная цель работы — на практике продемонстрировать, как изменения в настройках кластера и структуры запросов влияют на производительность базы данных.

**Цели и задачи исследования**

Целью данной работы является изучение и практическое применение методов оптимизации PostgreSQL для повышения производительности обработки данных. Для достижения поставленной цели необходимо решить следующие задачи:
1. Развернуть кластер PostgreSQL на виртуальной машине с ОС Manjaro Linux в VirtualBox.
2. Загрузить в базу данных информацию из предоставленных CSV-файлов.
3. Разработать SQL-запросы для анализа данных.
4. Провести первоначальную оценку их производительности с помощью `EXPLAIN ANALYZE`.
5. Оптимизировать конфигурацию кластера PostgreSQL в соответствии с доступными ресурсами виртуальной машины.
6. Создать и настроить индексы для повышения эффективности выполнения запросов.
7. Проанализировать и оптимизировать сами SQL-запросы.
8. Провести повторное тестирование и сравнить результаты до и после оптимизации.

Результаты работы позволят наглядно продемонстрировать влияние различных мер оптимизации на скорость выполнения запросов, а также получить практический опыт настройки и улучшения производительности PostgreSQL.



## Подготовка виртуальной машины и кластера постгрес.

  1) Скачиваю образ дистрибутива Linux с Официального сайта
  2) Создаю новую вм со стандартными настройками:
     
     <img src="https://github.com/user-attachments/assets/5e1d6cd0-f5fb-49e8-b9b5-cd742df7c2ea" alt="drawing" width="500"/>
     
     <img src="https://github.com/user-attachments/assets/15b0e3c6-3b76-4924-93be-17608f1566a5" alt="drawing" width="500"/>
     
     <img src="https://github.com/user-attachments/assets/c9523dd1-5490-4c54-a784-4e50908c7899" alt="drawing" width="500"/>

  3) Запускаю ВМ и устанавливаю ОС

     <img src="https://github.com/user-attachments/assets/4219c519-c9b7-4beb-898b-fc67e6145904" alt="drawing" width="500"/>

  4) Устанавливаю Postgres на ВМ: ``sudo pacman -S postgresql``
  5) Инициализирую кластер базы данных: ``sudo -u postgres initdb --locale=en_US.UTF-8 -D /var/lib/postgres/data``
  6) Запускаю PostgreSQL: ``sudo systemctl start postgresql``
  7) Проверяю статус кластера: ``sudo -u postgres pg_ctl status -D /var/lib/postgres/data``

     <img src="https://github.com/user-attachments/assets/4fb9418a-c40f-471f-8b06-e2ca6452e5f2" alt="drawing" width="500"/>

## Оптимизация. Шаг 1 - Импорт данных в PostgreSQL, нормализация и создание первичных ключей

  Оптимизация базы данных начинается с правильного импорта данных. 
  Данный дата-сет изначально создавался для обучения нейронных сетей, а потому структура данных не совсем подходит для работы с ними в БД, а также дата-сет содержит лишнюю (в рамках данной работы) информацию, такую как ссылки на изображения с обложками, подробное описание каждого сериала и др.
  
  **По этой причине необходимо произвести нормализацию и очистку данных, что значительно ускорит работу с данными.** 
  
  Я решил сделать это на этапе импорта данных, чтобы не возвращаться к этому в дальнейшем. 
  
  **Перечень полей для импорта по каждому файлу:**

  - Файл: ``anime-transformed-dataset-2023.csv``; Столбцы: ``id,title,genres,type,episodes,status,producers,licensors,studios,source,duration,rating,rank,popularity,favorites,scored_by,members,is_hentai``.
  - Файл: ``users-details-transformed-2023.csv``; Столбцы: ``id,name,gender,joined,days_watched,mean_score,watching,completed,on_hold,dropped,plan_to_watch,total_entries,rewatched,episodes_watched``.
  - Файл: ``users-scores-transformed-2023.csv``;  Столбцы: ``user_id,anime_id,rating``.

  Перед началом импорта данных необходимо создать в БД подходящую структуру:

  1) Создание новой базы данных: ``CREATE DATABASE anime_db;``
  2) Создание таблицы ``anime``:
```
     CREATE TABLE anime (
    id SERIAL PRIMARY KEY,
    title TEXT NOT NULL,
    genres TEXT,
    type TEXT,
    episodes INT,
    status TEXT,
    producers TEXT,
    licensors TEXT,
    studios TEXT,
    source TEXT,
    duration TEXT,
    rating TEXT,
    rank INT,
    popularity INT,
    favorites INT,
    scored_by INT,
    members INT,
    is_hentai BOOLEAN
    );
```
  3) Создание таблицы ``users``:
```
     CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    name TEXT NOT NULL,
    gender TEXT,
    joined TIMESTAMP WITH TIME ZONE,
    days_watched NUMERIC,
    mean_score NUMERIC(4,2),
    watching INT,
    completed INT,
    on_hold INT,
    dropped INT,
    plan_to_watch INT,
    total_entries INT,
    rewatched INT,
    episodes_watched INT
    );
```
  4) Создание таблицы ``user_scores``:
```
    CREATE TABLE user_scores (
    user_id INT REFERENCES users(id) ON DELETE CASCADE,
    anime_id INT REFERENCES anime(id) ON DELETE CASCADE,
    rating SMALLINT CHECK (rating BETWEEN 0 AND 10),
    PRIMARY KEY (user_id, anime_id)
    );
```

**Уже с этого момента начался процесс оптимизации, так как при создании структуры базы данных учитывается создание первичных ключей, без которых поиск данных в таблицах значительно замедлится.** 

  Теперь, когда в БД подготовлена структура данных можно приступать к импорту данных. Так как из файлов нужно импортировать не все, а только определенные столбцы, а стандартная утилита ``COPY`` это не поддерживает, то мною было принято решение сначала загрузить все данные во временную таблицу, а потом перелить только нужные данные в основную (чуть позже выяснилось, что это не лучшее решение). 

  **Скрипт для импорта данных из файла ``anime-transformed-dataset-2023.csv``:**
```
    CREATE TEMP TABLE anime_raw (
    col1 TEXT, col2 TEXT, col3 TEXT, col4 TEXT, col5 TEXT, col6 TEXT, col7 TEXT, col8 TEXT, col9 TEXT, col10 TEXT, 
    col11 TEXT, col12 TEXT, col13 TEXT, col14 TEXT, col15 TEXT, col16 TEXT, col17 TEXT, col18 TEXT, col19 TEXT, col20 TEXT, col21 TEXT
    );
    
    COPY anime_raw FROM '/mnt/data/anime-transformed-dataset-2023.csv'
    DELIMITER ',' CSV HEADER QUOTE '"' ESCAPE '"';
    
    INSERT INTO anime (id, title, genres, type, episodes, status, producers, licensors, studios, source, duration, rating, rank, popularity, favorites, scored_by, members, is_hentai)
    SELECT col1::INT, col2, col4, col6::INT, col7, col8, col9, col10, col11, col12, col13, col14, col15::INT, col16::INT, col17::INT, col18::INT, col19::INT,col21::BOOLEAN
    FROM anime_raw;
```

  Данные из файла ``users-details-transformed-2023.csv`` не нуждаются в очистке и нормализации, поэтому их можно импортировать полностью.
  
  **Скрипт для импорта данных из файла ``users-details-transformed-2023.csv``:**
```
    COPY users(id, name, gender, joined, days_watched, mean_score, watching, completed, on_hold, dropped, plan_to_watch, total_entries, rewatched, episodes_watched)
    FROM '/mnt/data/users-details-transformed-2023.csv'
    DELIMITER ','
    CSV HEADER QUOTE '"' ESCAPE '"';
```

  Изначально я попробовал импортировать данные из файла ``users-scores-transformed-2023.csv`` таким же образом, как и для первого файла, однако, так как временные таблицы в PostgreSQL храняться в оперативной памяти, а данный файл содержит больше всего информации, я столкнулся с переполнением оперативной памяти на виртуальной машине. Поэтому, вместо создания временной таблицы, будет создана обычная таблица для импорта всех данных из файла, а потом только необходимые данные будут загружены в основную таблицу. 
  
  **Скрипт для импорта данных из файла ``users-scores-transformed-2023.csv``:**
```
    CREATE TABLE usr_scr_tmp (
    col1 TEXT, col2 TEXT, col3 TEXT, col4 TEXT, col5 TEXT
    );

    COPY usr_scr_tmp FROM '/mnt/data/users-scores-transformed-2023.csv'
    DELIMITER ',' CSV HEADER QUOTE '"' ESCAPE '"';

    INSERT INTO user_scores (user_id, anime_id, rating)
    SELECT col1::INT, col3::INT, col5::SMALLINT
    FROM anime_raw;

    DROP TABLE usr_scr_tmp;
```

## Оптимизация. Шаг 2 - Оптимизация кода и контрольный замер производительности.

  Перед началом процесса оптимизации необходимо составить запрос, на примере которого будет производится вся последующая работа по оптимизации. 
  Для этой цели я составил следуюший запрос, который выводит 10 самых высоко-оцененных серилалов у определенного пользователя: 

```
    SELECT u.name, a.title, us.rating  -- Вывод имени пользователя, названия сериала, оценка пользователя
    FROM users u, user_scores us, anime a  -- используемые таблицы
    WHERE us.user_id = u.id
    AND us.anime_id = a.id
    AND (u.id = 3611)  -- указание пользователя
    AND us.rating > 0
    ORDER BY us.rating DESC, a.popularity DESC  -- сортировка
    LIMIT 10; -- ограничение 10 строк
```

  Данный запрос хорош тем, что использует сразу три имеющиеся таблицы, а значит последующая оптимизация затронет их все. 

  **Контрольный замер производительности с EXPLAIN ANALYZE:**

  <img src="https://github.com/user-attachments/assets/7db51444-2ad7-46bf-b378-340dde9d15c0" alt="drawing" width="500"/>

  Как видно, данный запрос имеет Planning Time: 1.921 ms, а также Execution Time: 114.510 ms.
  
  Однако в данном случае сам запрос не является оптимальным, так как составлен не лучшим образом. А именно, данный запрос использует устаревший синтаксис с WHERE вместо JOIN, что хуже оптимизируется,
  нет явного указания соединений JOIN, что увеличивает вероятность неэффективного выполнения.
  
  
  **Оптимизированный запрос:**
```
    SELECT u.name, a.title, us.rating
    FROM user_scores us
    JOIN users u ON us.user_id = u.id
    JOIN anime a ON us.anime_id = a.id
    WHERE (u.id = 3611)
    AND us.rating > 0
    ORDER BY us.rating DESC, a.popularity DESC
    LIMIT 10;
```
  Данный запрос выполняет туже задачу, но написан уже с учетом выявленных недостатков. 
  
  **Результат выполнения оптимизированного запроса:**

  <img src="https://github.com/user-attachments/assets/8a4fcf2a-865c-4cca-8a5e-35c9f074837e" alt="drawing" width="500"/>

  Обновленный, оптимизированный запрос уже имеет Planning Time: 0.320 ms (в 6 раз быстрее), а также Execution Time: 46.154 ms (в 2,5 раза быстрее). На данном примере было выявлено, что правильное написание запроса позволяет повысить его производительность более чем в 2 раза. 

  **Также рассмотрим пример где случайным образом изменяются оценки случайных пользователей в таблице user_scores:**
```
    UPDATE user_scores
    SET rating = FLOOR(RANDOM() * 11)  -- случайная оценка, число от 0 до 10
    WHERE (user_id, anime_id) IN (
        SELECT user_id, anime_id
        FROM user_scores
        TABLESAMPLE SYSTEM (5)  -- случайный выбор ~5% строк без полной сортировки
        LIMIT 50000  -- ограничиваем количество обновлений
    );
```

  **Результат выполнения скрипта обновления данных:**

  <img src="https://github.com/user-attachments/assets/9518eaf8-e6d6-4939-917a-f4e05367d381" alt="drawing" width="500"/>

  Данный запрос имеет Execution Time: 1136.088 ms
  
## Оптимизация. Шаг 3 - Настройка PostgreSQL.

  Для подбора оптимальных настроек для PostgreSQL использован сервис pgtune.leopard.in.ua. После указания характеристик виртуальной машины, сервис порекомендовал следующие настройки для кластера PostgreSQL:
```
    # DB Version: 17
    # OS Type: linux
    # DB Type: web
    # Total Memory (RAM): 8 GB
    # CPUs num: 3
    # Data Storage: ssd
    
    max_connections = 200
    shared_buffers = 2GB
    effective_cache_size = 6GB
    maintenance_work_mem = 512MB
    checkpoint_completion_target = 0.9
    wal_buffers = 16MB
    default_statistics_target = 100
    random_page_cost = 1.1
    effective_io_concurrency = 200
    work_mem = 5242kB
    huge_pages = off
    min_wal_size = 1GB
    max_wal_size = 4GB
```

  Внес изменения в файл конфигурации постгрес и перезагрузил кластер. 

## Оптимизация. Шаг 4 - Работа с индексами.

  Индексы – это ключевой инструмент оптимизации запросов в базе данных. Они позволяют значительно ускорить операции поиска, сортировки и фильтрации данных, сокращая  количество строк, которые требуется просмотреть при выполнении запроса.

  В первую очередь рассмотрим самую крупную таблицу ``user_scores``.
  **Скрипт для проверки наличия индексов:**
```
    -- Проверяем, есть ли индекс на user_scores(user_id)
    SELECT * FROM pg_indexes WHERE tablename = 'user_scores' AND indexname LIKE '%user_id%';
    
    -- Проверяем, есть ли индекс на user_scores(anime_id)
    SELECT * FROM pg_indexes WHERE tablename = 'user_scores' AND indexname LIKE '%anime_id%';
```

  **Результат работы скрипта:**

  <img src="https://github.com/user-attachments/assets/542dbcae-8d2e-4981-8717-d1a31a4c5941" alt="drawing" width="500"/>

  Как видно, на таблице ``user_scores`` отсутствуют индексы. Индексы на столбцах ``user_id`` и ``anime_id`` помогут быстрее находить строки в ``user_scores`` при соединении с ``users`` и ``anime``.

  **Создание индексов:**
```
    CREATE INDEX idx_user_scores_user_id ON user_scores (user_id);
    CREATE INDEX idx_user_scores_anime_id ON user_scores (anime_id);
```

  **Так же, для данного конкретного запроса я попробовал создать составной индекс:**
  
  ``CREATE INDEX idx_user_scores_user_id_rating ON user_scores (user_id, rating DESC);``

  Данный индекс ускорит фильтрацию (``WHERE user_id = 3611``), а так же ускорит сортировку (``ORDER BY rating DESC``).

  **Проверка результата выполнения EXPLAIN ANALYZE:**

  <img src="https://github.com/user-attachments/assets/26c5ba08-1765-4c7e-98aa-f64a3a51ff6f" alt="drawing" width="500"/>

  На данном этапе видно, что Planning Time практически не изменилось и составляет 0.309 ms (было 0.320 ms), однако Execution Time сократился аж до 0.154 ms (почти в 300 раз быстрее прежнего). 


  **Но теперь проверим производительность скрипта обновления данных:**

  <img src="https://github.com/user-attachments/assets/f16ac71c-c44e-4ba3-a3c9-848bc058678b" alt="drawing" width="500"/>

  Как видно Execution Time увеличился до 1343.255 ms (было 1136.088 ms), создание индексов, которые ускоряют поиск данных, негатвно повлияло на процесс изменения данных. 

  Но почему именно в нашем случае замедлился скрипт обновления данных? Данный скрипт обновляет поле ``rating``, на которое ранее был создан составной индекс. В запросах массового изменения данных структура индексов может продлевает отработку поскольку требует дополнительного времени на синхронизацию данных таблицы с индексами, для потдержания данных в индексах в актульаном состоянии.
  
  Для достижения наиболее оптимальной структуры, попробую удалить созданный ранее составной индекс, и понаблюдать как это повлияет на производительность обоих запросов. 

  ``DROP INDEX IF EXISTS idx_user_scores_user_id_rating;``

  **Результат скрипта обновления данных:**

  <img src="https://github.com/user-attachments/assets/b3b105b9-96bc-4210-8202-3fd9df8cc5bf" alt="drawing" width="500"/>

  Теперь время выполнения запроса вернулось к изначальному параметру и составляет 1105.453 ms. 

  **Проверка результата выполнения выборки:**

  <img src="https://github.com/user-attachments/assets/ed79bcc8-7746-438a-89ab-fbc5848760d8" alt="drawing" width="500"/>

  Время выполнения данного запроса немного увеличилось и составляет 0.371 ms, но зато теперь структура индексов меньше влияет на операции изменения данных. 


## Выводы по проделанной работе по оптимизации PostgreSQL

### **1. Оптимизация конфигурации PostgreSQL**
В результате изменения настроек кластера PostgreSQL были улучшены показатели производительности запросов. Основные изменения включали:
- **Настройку параметров памяти** (`shared_buffers`, `work_mem`, `maintenance_work_mem`), что позволило сократить количество обращений к диску.
- **Корректировку `random_page_cost`**, что улучшило планирование запросов с использованием индексов.
- **Тонкую настройку `effective_cache_size`**, позволившую оптимизатору лучше учитывать кэшируемые данные.

Эти изменения дали общий прирост производительности при выполнении выборок и обновлений данных.

---

### **2. Оптимизация запроса выборки данных**
Исходный запрос выборки имел неоптимальный план выполнения. В ходе оптимизации были предприняты следующие шаги:
- **Оптимизирован код запроса**.
- **Созданы индексы для ускорения фильтрации и сортировки**.
- **Использован `EXPLAIN ANALYZE`** для детального анализа производительности запроса.
- В результате время выполнения запроса выборки **сократилось с 114.51 ms до 0.371 ms (быстрее в 308 раз)**.

Таким образом, за счёт создания индексов и грамотной настройки параметров PostgreSQL удалось значительно ускорить работу SELECT-запросов.

---

### **3. Оптимизация массового обновления данных**
Изначально `UPDATE` выполнялся за **~1136.088 ms** на необработанной базе. После применения оптимизационных настроек этот же `UPDATE` стал выполняться за **1343.255 ms**, что указывало на неожиданное замедление.

Причина замедления была выявлена:
- **Индекс `idx_user_scores_user_id_rating` негативно влиял на обновления**, так как включал `rating`, который изменялся в `UPDATE`.
- Из-за этого PostgreSQL вынужден был обновлять не только данные, но и индекс, что приводило к дополнительным затратам.

После удаления составного индекса `idx_user_scores_user_id_rating` производительность `UPDATE` вернулась к изначальному значению **(~1105.453 ms)**. Однако, как следствие, скорость выполнения выборки **слегка увеличилась** (до 0.371 ms), но в разумных пределах.

Таким образом, было найдено оптимальное решение: **жертвовать минимальным увеличением времени выборки ради ускорения массовых обновлений**.

---

### **4. Общие выводы**
- **Оптимизация конфигурации PostgreSQL** привела к общему ускорению запросов.
- **Индексы значительно ускоряют выборку**, но **могут замедлять обновление данных**.
- **Удаление неэффективного индекса** позволило вернуть скорость `UPDATE` к изначальному значению, минимально увеличив время выполнения выборки.
- **Анализ с `EXPLAIN ANALYZE` и `pg_stat_statements` помог в выявлении узких мест** и оценке влияния изменений.

В итоге удалось найти **баланс между скоростью выборки и обновления данных**, что позволило значительно повысить общую производительность базы данных.

---

### Цель достигнута!

---

## Что дальше? 

  На данном этапе удалось достичь положительных результатов по оптимизации базы данных, а также, в процессе, была проведена внушительная работа по исследованию темы оптимизации баз данных. 
  Тем не менее в рамках данной проектной работы не было использованно всех полученных теоритических знаний и практических навыков. Но срок сдачи данной проектной работы ограничен. По этой причине дальнейшая работа над данным проектом не может быть продолжена.

  ---

  **Но все же я хочу привести перечень дополнительных действий, к которым можно прибегнуть для еще большего улучшения оптимизации:**

1. **Оптимизация хранения данных**  
   - Рассмотреть возможность использования **PARTITION BY** для `user_scores`, так как база содержит очень много данных.  
   - Сжатие таблиц с помощью **pg_compress** или выбор подходящего метода хранения.  

2. **Мониторинг и анализ производительности (в рамках производственной среды)**  
   - Настроить **pg_stat_statements** для анализа наиболее ресурсоемких запросов.  
   - Использовать **auto_explain** для выявления скрытых проблем в запросах.  

3. **Дополнительная индексация**  
   - Исследовать **BRIN-индексы** вместо B-Tree для `user_scores`, если данные имеют хорошую корреляцию.  
   - Попробовать **GIN/GiST-индексы**, если появится работа с JSON или full-text search.  

4. **Настройка параметров PostgreSQL**  
   - Тестировать изменения **work_mem**, **random_page_cost**, **effective_cache_size** и других параметров, влияющих на планы выполнения запросов.  

5. **Многопоточная обработка обновлений**  
   - Использовать **batch updates** или **декомпозицию транзакций** для массовых обновлений данных.  
   - Рассмотреть **параллельное обновление** через `UPDATE ... FROM` или `CTE`.  

6. **Тестирование на боевых данных**  
   - Запустить тестирование с **реальной нагрузкой**, симулировать конкурентные обновления и запросы.  
   - Анализировать **журнал медленных запросов** и проводить A/B-тестирование оптимизаций.  

